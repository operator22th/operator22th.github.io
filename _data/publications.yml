main:
  - title: "RLVR-World: Training World Models with Reinforcement Learning"
    authors: Jialong Wu, <strong>Shaofeng Yin</strong>, Ningya Feng, Mingsheng Long
    conference_short: arXiv
    conference: arXiv preprint, 2025.
    arxiv: https://arxiv.org/abs/2505.13934
    pdf: https://arxiv.org/pdf/2505.13934
    code: https://github.com/thuml/RLVR-World
    page: https://thuml.github.io/RLVR-World/
    image: ./assets/pub/arxiv2025_rlvr-world/rlvr_world.png
    research_question: <strong>Research question:</strong> How can we train world models to better serve downstream tasks, beyond mere transition modeling?
    key_features: <strong>Key features:</strong> RLVR training; strong improvements on language and video world models across text games, web navigation, and <strong>robot manipulation</strong>.

  - title: "Trajectory World Models for Heterogeneous Environments"
    authors: <strong>Shaofeng Yin*</strong>, Jialong Wu*, Siqiao Huang, Xingjian Su, Xu He, Jianye Hao, Mingsheng Long
    conference_short: ICML
    conference: International Conference on Machine Learning (<strong>ICML</strong>), 2025.
    arxiv: https://arxiv.org/abs/2502.01366
    pdf: https://arxiv.org/pdf/2502.01366
    code: https://github.com/thuml/TrajWorld
    image: ./assets/pub/arxiv2025_trajworld/trajworld.png
    research_question: <strong>Research question:</strong> How can we build generalizable sensor-based world models across diverse environments?
    key_features: <strong>Key features:</strong> pretrained proprioceptive world model; single model for all robots; strong transferability; significant improvements in  MPC and OPE on <strong>locomotion</strong> tasks.

  - title: "iVideoGPT: Interactive VideoGPTs are Scalable World Models"
    authors: Jialong Wu*, <strong>Shaofeng Yin*</strong>, Ningya Feng, Xu He, Dong Li, Jianye Hao, Mingsheng Long
    conference_short: Neurlps
    conference: Conference on Neural Information Processing Systems <strong>(Neurlps)</strong>, 2024.
    pdf: https://arxiv.org/pdf/2405.15223.pdf
    code: https://github.com/thuml/iVideoGPT
    page: https://thuml.github.io/iVideoGPT/
    image: ./assets/pub/nips2024_ivideogpt/ivideogpt.png
    research_question: <strong>Research question:</strong> How can we leverage the advancements in scalable video generative models for developing interactive visual world models?
    key_features: <strong>Key features:</strong> pretrained visual world model; unified model for diverse robot arms; strong transferability; high efficiency; significant improvements across MPC and MBRL on <strong>manipulation</strong> tasks.
